# SCARP25_ARISE - Weekly Journals

## Table of Contents
- [Week 1](#Week_1)

## Week 1:
### Day 1:
Focused on getting a deeper general understanding for the project and its intended direction as well as a better feel for the features that we want implemented for this summers research. Additionally division of work to make sure that there as an equal distribution for each of our ecxpereince levels and comfortability with the different tasks at hand. Aaron has a better understanding of hardware than me and I plan on learning from him these first couple of days to better understand how to work with hardware. The main focus for today was to get the Jetson Nano devices to run and connect to a monitor for display. To do this we had to troubleshoot power issues as well as make sure that the pin outs of the SDK are working as intended with the diffferent attachments such as the fan for cooling the GPU. Additionally once able to diplay the information from the devices onto a monitor we were then able to check the software capabilities of the SDK's as we have to ensure the drivers and softwares installed are up to date and compatible with the models that we intend on implementing. For instance the Jetson Nano device from seed studio was running on ubuntu 18 which is outdated for most software packages. 

### Day 2: 
Starting day 2 the focus was updating Ubuntu as well as increasing the amount of swap space, to prevent memory errors when running out of RAM. While attempting to update Ubuntu, I had to connect the Jetson Nano to the internet and through this process realied that the decives had to be registered by the campus to be used on the internet. Therefore even with a wired connection we werent able to access the internet to get the necessary files needed for updating Ubuntu. Due to this, I started a focus on how we are going to incorperate text to speech into our system. Today I did research as well as implemented test files using Vosk, a text to speech model based on neural networks, and was able to have test files for both microhpone input as well as from an audio file such as MP4. Specifically Vosk models work with .wav files but the majority of examples that I found were converting MP4s to wav and then predicting on the data to determine what is being said. The microphone input is what is more suited towards our project, as it is offline speech to text deciphering, though using the microphone makes it hard to test edge cases like accents and background noise. Therefore I spent a good amount of time also just looking for audio files that either had background noise, making it harder to understand the words, or someone with a thick accent speaking. Doing this to then go back and test on the audio files to see the threshold at which background noise becomes too much, or where an accent is too thick, as well as different approaches to mitigate these.

### Day 3:
Today I wanted to take my focus back onto the Jetson Nano device as Aaron was able to connect his device to the wifi early on in the day. While Aaron was working on connecting his device to the internet, I worked on applying different english models for Vosk that we could use for Speech to text recognition. The intention of using all the latest available english models was to find which model worked the best for audio that may have an accent or background noise during its processing. This is due to the fact that many people have varrying accents as well as the background noise in different enviornments vary, and in the instance that someone has a thicker accent or lives in a busier, louder area, we wouldnt want our product being unintentionally discriminitory for those populations. I found that the larger the model the more time it would take to startup the model, as there is more information that needs to be loaded, though the larger models tended to struggle with audio that had an accent present. This could be due to the fact that Vosk models are Nueral Networks which have a tendency to overfit to their training data. Therefore having a larger model of a Nueral Network, which already has a tendency to overfit, could lead to even more overfitting errors. In the case of the audio files I was using for testing the larger models tended to struggle with larger words due to accents, and tried breaking them down into smaller easeir to determine words, that although may sound the same or similar to what was intended just gramatically wouldn't make sense. When it came to testing background noise though, there seemed to be an inverted bell curve for what could be called accuracy. For the audio with background noise I more so determined the success by how well the models were able to pickup any words that were said over a loud background. In this case the smaller models and the larger models were able to pickup on generally more words while the models in the middle were less likely to pickup words being said. Overall leading to my determination that we should use the Vosk's english graph model for implementation as it has a balance between accruacy, detection, and startup speed that would be realistic for our project's intentions. Finally after working on model selection, I attempted to connect my Jetson Nano to the internet and seemed to be able to. Once one the device I tried installing the software update for Ubuntu 20.04 though when the system rebooted the GUI was no longer working. I spent the rest fo the time trying to fix te GUI and may have to revert the software update to fix the packages that may have been corrupted.
  